{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8031498,"sourceType":"datasetVersion","datasetId":4733994},{"sourceId":8032375,"sourceType":"datasetVersion","datasetId":4734646}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\n!pip install pip==24.0\n!pip install accelerate==0.28.0\n!pip install bitsandbytes==0.43.0\n!pip install numpy==1.26.4\n!pip install pandas==2.2.1\n!pip install scikit-learn==1.4.1.post1\n!pip install scikit-multilearn==0.2.0\n!pip install transformers==4.38.2\n!pip install peft==0.9.0\n!pip install torch==2.2.1\n\"\"\"\n\n!python -m pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:35:42.915052Z","iopub.execute_input":"2024-04-07T18:35:42.915684Z","iopub.status.idle":"2024-04-07T18:35:42.930159Z","shell.execute_reply.started":"2024-04-07T18:35:42.91565Z","shell.execute_reply":"2024-04-07T18:35:42.92917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:36:09.99858Z","iopub.execute_input":"2024-04-07T18:36:09.998886Z","iopub.status.idle":"2024-04-07T18:36:22.84868Z","shell.execute_reply.started":"2024-04-07T18:36:09.99886Z","shell.execute_reply":"2024-04-07T18:36:22.847566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:36:22.851558Z","iopub.execute_input":"2024-04-07T18:36:22.851874Z","iopub.status.idle":"2024-04-07T18:36:39.082381Z","shell.execute_reply.started":"2024-04-07T18:36:22.851847Z","shell.execute_reply":"2024-04-07T18:36:39.081479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:36:39.083972Z","iopub.execute_input":"2024-04-07T18:36:39.084859Z","iopub.status.idle":"2024-04-07T18:36:51.533485Z","shell.execute_reply.started":"2024-04-07T18:36:39.08482Z","shell.execute_reply":"2024-04-07T18:36:51.532545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade -q wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:36:51.535031Z","iopub.execute_input":"2024-04-07T18:36:51.535386Z","iopub.status.idle":"2024-04-07T18:37:07.610177Z","shell.execute_reply.started":"2024-04-07T18:36:51.535353Z","shell.execute_reply":"2024-04-07T18:37:07.609088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label. \n# If you use some other Label make sure to change the same below. \nwandb_api = user_secrets.get_secret(\"wandb_api\") \n\nwandb.login(key=wandb_api)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:37:07.611669Z","iopub.execute_input":"2024-04-07T18:37:07.611997Z","iopub.status.idle":"2024-04-07T18:37:10.408457Z","shell.execute_reply.started":"2024-04-07T18:37:07.61197Z","shell.execute_reply":"2024-04-07T18:37:10.407501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, hamming_loss\nfrom datasets import Dataset, DatasetDict\nfrom peft import (\n    LoraConfig,\n    prepare_model_for_kbit_training,\n    get_peft_model\n)\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    get_linear_schedule_with_warmup\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:37:10.409543Z","iopub.execute_input":"2024-04-07T18:37:10.409945Z","iopub.status.idle":"2024-04-07T18:37:30.265505Z","shell.execute_reply.started":"2024-04-07T18:37:10.40992Z","shell.execute_reply":"2024-04-07T18:37:30.264696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:37:30.266708Z","iopub.execute_input":"2024-04-07T18:37:30.267703Z","iopub.status.idle":"2024-04-07T18:37:30.272212Z","shell.execute_reply.started":"2024-04-07T18:37:30.267667Z","shell.execute_reply":"2024-04-07T18:37:30.271195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seed for reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:41:42.548622Z","iopub.execute_input":"2024-04-07T18:41:42.549037Z","iopub.status.idle":"2024-04-07T18:41:42.558149Z","shell.execute_reply.started":"2024-04-07T18:41:42.549007Z","shell.execute_reply":"2024-04-07T18:41:42.55712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/baseline-dataset/baseline_dataset.csv')\n\n# Preprocess the category column for multi-label classification\ncategory_labels = pd.get_dummies(df['category'])\ndf = df.join(category_labels)\n\n# Split the DataFrame into separate DataFrames for each category\ncategory_0 = df[df['category'] == 0]\ncategory_1 = df[df['category'] == 1]\ncategory_2 = df[df['category'] == 2]\n\n# Sample approximately 3333 from each category\nsample_size = 3333\ncategory_0_sample = category_0.sample(n=sample_size+1, random_state=1)\ncategory_1_sample = category_1.sample(n=sample_size, random_state=1)\ncategory_2_sample = category_2.sample(n=sample_size, random_state=1)\n\n# Combine and shuffle the samples\ndf = pd.concat([category_0_sample, category_1_sample, category_2_sample])\ndf = df.sample(frac=1, random_state=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:43:00.341768Z","iopub.execute_input":"2024-04-07T18:43:00.342167Z","iopub.status.idle":"2024-04-07T18:43:00.431773Z","shell.execute_reply.started":"2024-04-07T18:43:00.342138Z","shell.execute_reply":"2024-04-07T18:43:00.430963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('label', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:43:00.886905Z","iopub.execute_input":"2024-04-07T18:43:00.887274Z","iopub.status.idle":"2024-04-07T18:43:00.893494Z","shell.execute_reply.started":"2024-04-07T18:43:00.887245Z","shell.execute_reply":"2024-04-07T18:43:00.892533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:43:01.357936Z","iopub.execute_input":"2024-04-07T18:43:01.358294Z","iopub.status.idle":"2024-04-07T18:43:01.372836Z","shell.execute_reply.started":"2024-04-07T18:43:01.358271Z","shell.execute_reply":"2024-04-07T18:43:01.371731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:43:02.054416Z","iopub.execute_input":"2024-04-07T18:43:02.055336Z","iopub.status.idle":"2024-04-07T18:43:02.063686Z","shell.execute_reply.started":"2024-04-07T18:43:02.055303Z","shell.execute_reply":"2024-04-07T18:43:02.062655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into text and multiple labels\ntext = df['claim'].values\n# Update: Extract labels from the sampled df\nlabels = df[category_labels.columns].values","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:44:23.136626Z","iopub.execute_input":"2024-04-07T18:44:23.137397Z","iopub.status.idle":"2024-04-07T18:44:23.143323Z","shell.execute_reply.started":"2024-04-07T18:44:23.137357Z","shell.execute_reply":"2024-04-07T18:44:23.142348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class weights for multi-label classification\nclass_counts = np.sum(labels, axis=0)\nclass_weights = [len(labels) / class_counts[i] for i in range(len(class_counts))]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:44:24.811489Z","iopub.execute_input":"2024-04-07T18:44:24.811871Z","iopub.status.idle":"2024-04-07T18:44:24.81694Z","shell.execute_reply.started":"2024-04-07T18:44:24.811841Z","shell.execute_reply":"2024-04-07T18:44:24.815931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\nx_train, x_val, y_train, y_val = train_test_split(text, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:44:26.038833Z","iopub.execute_input":"2024-04-07T18:44:26.039189Z","iopub.status.idle":"2024-04-07T18:44:26.046272Z","shell.execute_reply.started":"2024-04-07T18:44:26.039162Z","shell.execute_reply":"2024-04-07T18:44:26.045462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Hugging Face datasets\nds = DatasetDict({\n    'train': Dataset.from_dict({'text': x_train, 'labels': y_train}),\n    'val': Dataset.from_dict({'text': x_val, 'labels': y_val})\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:44:35.60236Z","iopub.execute_input":"2024-04-07T18:44:35.603122Z","iopub.status.idle":"2024-04-07T18:44:35.636889Z","shell.execute_reply.started":"2024-04-07T18:44:35.603088Z","shell.execute_reply":"2024-04-07T18:44:35.636097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model name\nmodel_name = 'mistralai/Mistral-7B-v0.1'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:44:36.820444Z","iopub.execute_input":"2024-04-07T18:44:36.820793Z","iopub.status.idle":"2024-04-07T18:44:38.190282Z","shell.execute_reply.started":"2024-04-07T18:44:36.82077Z","shell.execute_reply":"2024-04-07T18:44:38.189456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess dataset with tokenizer\ndef tokenize_examples(examples, tokenizer):\n    tokenized_inputs = tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n    tokenized_inputs['labels'] = examples['labels']\n    return tokenized_inputs\n\ntokenized_ds = ds.map(functools.partial(tokenize_examples, tokenizer=tokenizer), batched=True)\ntokenized_ds = tokenized_ds.with_format('torch')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:44:38.191786Z","iopub.execute_input":"2024-04-07T18:44:38.192065Z","iopub.status.idle":"2024-04-07T18:44:39.395405Z","shell.execute_reply.started":"2024-04-07T18:44:38.192041Z","shell.execute_reply":"2024-04-07T18:44:39.394431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# qunatization config\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\n# lora config\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)\n\n# load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=category_labels.shape[1]\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:44:39.397334Z","iopub.execute_input":"2024-04-07T18:44:39.397807Z","iopub.status.idle":"2024-04-07T18:46:09.907225Z","shell.execute_reply.started":"2024-04-07T18:44:39.397726Z","shell.execute_reply":"2024-04-07T18:46:09.90615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define custom batch preprocessor\ndef collate_fn(batch, tokenizer):\n    dict_keys = ['input_ids', 'attention_mask', 'labels']\n    d = {k: [dic[k] for dic in batch] for k in dict_keys}\n    d['input_ids'] = torch.nn.utils.rnn.pad_sequence(\n        d['input_ids'], batch_first=True, padding_value=tokenizer.pad_token_id\n    )\n    d['attention_mask'] = torch.nn.utils.rnn.pad_sequence(\n        d['attention_mask'], batch_first=True, padding_value=0\n    )\n    d['labels'] = torch.stack(d['labels'])\n    return d\n\n# Custom Trainer for handling class weights in binary classification\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        # Ensure labels are in float format\n        labels = labels.type(torch.float32)\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n    \n# Metrics computation for binary classification\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()\n    thresholded_preds = predictions > 0.5\n    f1 = f1_score(labels, thresholded_preds, average='weighted')\n    accuracy = accuracy_score(labels, thresholded_preds)\n    hamming = hamming_loss(labels, thresholded_preds)\n\n    metrics = {\n        'f1_score': f1,\n        'accuracy': accuracy,\n        'hamming_loss': hamming\n    }\n\n    wandb.log(metrics)\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:47:30.987345Z","iopub.execute_input":"2024-04-07T18:47:30.987703Z","iopub.status.idle":"2024-04-07T18:47:31.000886Z","shell.execute_reply.started":"2024-04-07T18:47:30.987678Z","shell.execute_reply":"2024-04-07T18:47:30.999711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training args with gradient accumulation, learning rate scheduler, and early stopping\ntraining_args = TrainingArguments(\n    output_dir='category_binary_mistral_All',\n    learning_rate=1e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    gradient_accumulation_steps=2,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy='steps',\n    eval_steps=50,\n    save_steps=50,\n    load_best_model_at_end=True,\n    logging_steps=100,\n    fp16=True,\n    report_to='wandb',  # Enable wandb logging\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:47:31.520307Z","iopub.execute_input":"2024-04-07T18:47:31.52107Z","iopub.status.idle":"2024-04-07T18:47:31.528594Z","shell.execute_reply.started":"2024-04-07T18:47:31.521039Z","shell.execute_reply":"2024-04-07T18:47:31.527335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the number of training steps for the scheduler\nnum_training_steps = (len(tokenized_ds['train']) // training_args.per_device_train_batch_size) * training_args.num_train_epochs\n\n# Initialize optimizer and scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=0, \n    num_training_steps=num_training_steps\n)\n\n# Initialize the Trainer\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds['train'],\n    eval_dataset=tokenized_ds['val'],\n    tokenizer=tokenizer,\n    data_collator=functools.partial(collate_fn, tokenizer=tokenizer),\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, scheduler)\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:47:31.883723Z","iopub.execute_input":"2024-04-07T18:47:31.884649Z","iopub.status.idle":"2024-04-07T18:47:31.909495Z","shell.execute_reply.started":"2024-04-07T18:47:31.884619Z","shell.execute_reply":"2024-04-07T18:47:31.908422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.object = object\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:47:32.339591Z","iopub.execute_input":"2024-04-07T18:47:32.340636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save and load model\npeft_model_id = 'category_binary_mistral_All'","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:37:31.145847Z","iopub.status.idle":"2024-04-07T18:37:31.146148Z","shell.execute_reply.started":"2024-04-07T18:37:31.145997Z","shell.execute_reply":"2024-04-07T18:37:31.14601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T18:37:31.147365Z","iopub.status.idle":"2024-04-07T18:37:31.147662Z","shell.execute_reply.started":"2024-04-07T18:37:31.147512Z","shell.execute_reply":"2024-04-07T18:37:31.147525Z"},"trusted":true},"execution_count":null,"outputs":[]}]}