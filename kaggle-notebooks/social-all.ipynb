{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8031498,"sourceType":"datasetVersion","datasetId":4733994},{"sourceId":8032375,"sourceType":"datasetVersion","datasetId":4734646}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\n!pip install pip==24.0\n!pip install accelerate==0.28.0\n!pip install bitsandbytes==0.43.0\n!pip install numpy==1.26.4\n!pip install pandas==2.2.1\n!pip install scikit-learn==1.4.1.post1\n!pip install scikit-multilearn==0.2.0\n!pip install transformers==4.38.2\n!pip install peft==0.9.0\n!pip install torch==2.2.1\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:50:59.038142Z","iopub.execute_input":"2024-04-07T04:50:59.03899Z","iopub.status.idle":"2024-04-07T04:50:59.059455Z","shell.execute_reply.started":"2024-04-07T04:50:59.038949Z","shell.execute_reply":"2024-04-07T04:50:59.058435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:50:59.061476Z","iopub.execute_input":"2024-04-07T04:50:59.062285Z","iopub.status.idle":"2024-04-07T04:51:23.451633Z","shell.execute_reply.started":"2024-04-07T04:50:59.062253Z","shell.execute_reply":"2024-04-07T04:51:23.450719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:51:23.452987Z","iopub.execute_input":"2024-04-07T04:51:23.453312Z","iopub.status.idle":"2024-04-07T04:51:36.00285Z","shell.execute_reply.started":"2024-04-07T04:51:23.453282Z","shell.execute_reply":"2024-04-07T04:51:36.001794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:51:36.005433Z","iopub.execute_input":"2024-04-07T04:51:36.005753Z","iopub.status.idle":"2024-04-07T04:51:51.644452Z","shell.execute_reply.started":"2024-04-07T04:51:36.005722Z","shell.execute_reply":"2024-04-07T04:51:51.643338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:51:51.646793Z","iopub.execute_input":"2024-04-07T04:51:51.647064Z","iopub.status.idle":"2024-04-07T04:52:03.818761Z","shell.execute_reply.started":"2024-04-07T04:51:51.647037Z","shell.execute_reply":"2024-04-07T04:52:03.817607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade -q wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:03.820215Z","iopub.execute_input":"2024-04-07T04:52:03.820516Z","iopub.status.idle":"2024-04-07T04:52:19.526808Z","shell.execute_reply.started":"2024-04-07T04:52:03.820487Z","shell.execute_reply":"2024-04-07T04:52:19.525626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label. \n# If you use some other Label make sure to change the same below. \nwandb_api = user_secrets.get_secret(\"wandb_api\") \n\nwandb.login(key=wandb_api)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:19.530503Z","iopub.execute_input":"2024-04-07T04:52:19.530827Z","iopub.status.idle":"2024-04-07T04:52:23.148649Z","shell.execute_reply.started":"2024-04-07T04:52:19.530794Z","shell.execute_reply":"2024-04-07T04:52:23.147673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\nfrom datasets import Dataset, DatasetDict\nfrom peft import (\n    LoraConfig,\n    prepare_model_for_kbit_training,\n    get_peft_model\n)\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    get_linear_schedule_with_warmup\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:23.150014Z","iopub.execute_input":"2024-04-07T04:52:23.150544Z","iopub.status.idle":"2024-04-07T04:52:41.90172Z","shell.execute_reply.started":"2024-04-07T04:52:23.150509Z","shell.execute_reply":"2024-04-07T04:52:41.900943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:41.902842Z","iopub.execute_input":"2024-04-07T04:52:41.903594Z","iopub.status.idle":"2024-04-07T04:52:41.907928Z","shell.execute_reply.started":"2024-04-07T04:52:41.903566Z","shell.execute_reply":"2024-04-07T04:52:41.906925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seed for reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:41.911478Z","iopub.execute_input":"2024-04-07T04:52:41.911752Z","iopub.status.idle":"2024-04-07T04:52:41.945129Z","shell.execute_reply.started":"2024-04-07T04:52:41.911729Z","shell.execute_reply":"2024-04-07T04:52:41.944204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/baseline-dataset/baseline_dataset.csv')\n\n#df grab 3000 rows from category 1 (0 Health, 1 Politics, 2 Social)\ndf = df[df['category'] == 2]\n\n# print the distrubution of the dataset\nprint(df['category'].value_counts())\nprint(df['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:41.946211Z","iopub.execute_input":"2024-04-07T04:52:41.946473Z","iopub.status.idle":"2024-04-07T04:52:42.098577Z","shell.execute_reply.started":"2024-04-07T04:52:41.94645Z","shell.execute_reply":"2024-04-07T04:52:42.09764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('category', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.099795Z","iopub.execute_input":"2024-04-07T04:52:42.10017Z","iopub.status.idle":"2024-04-07T04:52:42.10582Z","shell.execute_reply.started":"2024-04-07T04:52:42.100134Z","shell.execute_reply":"2024-04-07T04:52:42.104912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.107141Z","iopub.execute_input":"2024-04-07T04:52:42.107475Z","iopub.status.idle":"2024-04-07T04:52:42.116817Z","shell.execute_reply.started":"2024-04-07T04:52:42.107444Z","shell.execute_reply":"2024-04-07T04:52:42.116064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df display unique values in label column\nprint(df['label'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.117819Z","iopub.execute_input":"2024-04-07T04:52:42.118113Z","iopub.status.idle":"2024-04-07T04:52:42.131889Z","shell.execute_reply.started":"2024-04-07T04:52:42.118072Z","shell.execute_reply":"2024-04-07T04:52:42.131003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into text and labels\ntext = df['claim'].values\nlabels = df['label'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.133037Z","iopub.execute_input":"2024-04-07T04:52:42.133388Z","iopub.status.idle":"2024-04-07T04:52:42.141149Z","shell.execute_reply.started":"2024-04-07T04:52:42.133358Z","shell.execute_reply":"2024-04-07T04:52:42.140332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class weights for binary classification\nclass_counts = np.bincount(labels)\nclass_weights = torch.tensor([len(labels) / class_counts[1], len(labels) / class_counts[0]], dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.142048Z","iopub.execute_input":"2024-04-07T04:52:42.142311Z","iopub.status.idle":"2024-04-07T04:52:42.150788Z","shell.execute_reply.started":"2024-04-07T04:52:42.14229Z","shell.execute_reply":"2024-04-07T04:52:42.149924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\nx_train, x_val, y_train, y_val = train_test_split(text, labels, test_size=0.1, stratify=labels, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.151959Z","iopub.execute_input":"2024-04-07T04:52:42.152253Z","iopub.status.idle":"2024-04-07T04:52:42.162971Z","shell.execute_reply.started":"2024-04-07T04:52:42.152223Z","shell.execute_reply":"2024-04-07T04:52:42.162127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Hugging Face datasets\nds = DatasetDict({\n    'train': Dataset.from_dict({'text': x_train, 'labels': y_train}),\n    'val': Dataset.from_dict({'text': x_val, 'labels': y_val})\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.16404Z","iopub.execute_input":"2024-04-07T04:52:42.165645Z","iopub.status.idle":"2024-04-07T04:52:42.188276Z","shell.execute_reply.started":"2024-04-07T04:52:42.16562Z","shell.execute_reply":"2024-04-07T04:52:42.187519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model name\nmodel_name = 'mistralai/Mistral-7B-v0.1'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:42.189295Z","iopub.execute_input":"2024-04-07T04:52:42.189547Z","iopub.status.idle":"2024-04-07T04:52:46.868699Z","shell.execute_reply.started":"2024-04-07T04:52:42.189525Z","shell.execute_reply":"2024-04-07T04:52:46.867907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess dataset with tokenizer\ndef tokenize_examples(examples, tokenizer):\n    tokenized_inputs = tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n    tokenized_inputs['labels'] = examples['labels']\n    return tokenized_inputs\n\ntokenized_ds = ds.map(functools.partial(tokenize_examples, tokenizer=tokenizer), batched=True)\ntokenized_ds = tokenized_ds.with_format('torch')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:46.869823Z","iopub.execute_input":"2024-04-07T04:52:46.870129Z","iopub.status.idle":"2024-04-07T04:52:47.722564Z","shell.execute_reply.started":"2024-04-07T04:52:46.870093Z","shell.execute_reply":"2024-04-07T04:52:47.721668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# qunatization config\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\n# lora config\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)\n\n# load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=1\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-07T04:52:47.723758Z","iopub.execute_input":"2024-04-07T04:52:47.724035Z","iopub.status.idle":"2024-04-07T05:04:10.878331Z","shell.execute_reply.started":"2024-04-07T04:52:47.724011Z","shell.execute_reply":"2024-04-07T05:04:10.87752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define custom batch preprocessor\ndef collate_fn(batch, tokenizer):\n    dict_keys = ['input_ids', 'attention_mask', 'labels']\n    d = {k: [dic[k] for dic in batch] for k in dict_keys}\n    d['input_ids'] = torch.nn.utils.rnn.pad_sequence(\n        d['input_ids'], batch_first=True, padding_value=tokenizer.pad_token_id\n    )\n    d['attention_mask'] = torch.nn.utils.rnn.pad_sequence(\n        d['attention_mask'], batch_first=True, padding_value=0\n    )\n    d['labels'] = torch.stack(d['labels'])\n    return d\n\n# Custom Trainer for handling class weights in binary classification\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        if logits.shape[-1] == 1:\n            logits = logits.squeeze(-1)\n        labels = labels.float()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\n# Metrics computation for binary classification\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()\n    predictions = np.round(predictions)  # Threshold at 0.5\n    precision = precision_score(labels, predictions)\n    recall = recall_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average='weighted')\n    accuracy = accuracy_score(labels, predictions)\n\n    metrics = {\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'accuracy': accuracy\n    }\n\n    wandb.log(metrics)\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:04:10.879464Z","iopub.execute_input":"2024-04-07T05:04:10.879754Z","iopub.status.idle":"2024-04-07T05:04:10.891296Z","shell.execute_reply.started":"2024-04-07T05:04:10.879729Z","shell.execute_reply":"2024-04-07T05:04:10.890296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training args with gradient accumulation, learning rate scheduler, and early stopping\ntraining_args = TrainingArguments(\n    output_dir='Social_binary_mistral_All',\n    learning_rate=1e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    gradient_accumulation_steps=2,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy='steps',\n    eval_steps=50,\n    save_steps=50,\n    load_best_model_at_end=True,\n    logging_steps=100,\n    fp16=True,\n    report_to='wandb',  # Enable wandb logging\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:04:10.892518Z","iopub.execute_input":"2024-04-07T05:04:10.892878Z","iopub.status.idle":"2024-04-07T05:04:10.908194Z","shell.execute_reply.started":"2024-04-07T05:04:10.892849Z","shell.execute_reply":"2024-04-07T05:04:10.907346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the number of training steps for the scheduler\nnum_training_steps = (len(tokenized_ds['train']) // training_args.per_device_train_batch_size) * training_args.num_train_epochs\n\n# Initialize optimizer and scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=0, \n    num_training_steps=num_training_steps\n)\n\n# Initialize the Trainer\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds['train'],\n    eval_dataset=tokenized_ds['val'],\n    tokenizer=tokenizer,\n    data_collator=functools.partial(collate_fn, tokenizer=tokenizer),\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, scheduler)\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:04:10.909295Z","iopub.execute_input":"2024-04-07T05:04:10.909527Z","iopub.status.idle":"2024-04-07T05:04:10.941028Z","shell.execute_reply.started":"2024-04-07T05:04:10.909506Z","shell.execute_reply":"2024-04-07T05:04:10.94016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.object = object\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:04:10.942214Z","iopub.execute_input":"2024-04-07T05:04:10.942879Z","iopub.status.idle":"2024-04-07T05:04:59.044456Z","shell.execute_reply.started":"2024-04-07T05:04:10.942845Z","shell.execute_reply":"2024-04-07T05:04:59.038152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save and load model\npeft_model_id = 'Social_binary_mistral_All'","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:04:59.045562Z","iopub.status.idle":"2024-04-07T05:04:59.046059Z","shell.execute_reply.started":"2024-04-07T05:04:59.045816Z","shell.execute_reply":"2024-04-07T05:04:59.045838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:04:59.0528Z","iopub.status.idle":"2024-04-07T05:04:59.05384Z","shell.execute_reply.started":"2024-04-07T05:04:59.053651Z","shell.execute_reply":"2024-04-07T05:04:59.05367Z"},"trusted":true},"execution_count":null,"outputs":[]}]}