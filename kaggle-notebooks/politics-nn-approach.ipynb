{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8031498,"sourceType":"datasetVersion","datasetId":4733994}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Bidirectional\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.callbacks import EarlyStopping, TensorBoard\nimport os\nimport datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T20:46:06.469463Z","iopub.execute_input":"2024-04-18T20:46:06.470377Z","iopub.status.idle":"2024-04-18T20:46:06.478301Z","shell.execute_reply.started":"2024-04-18T20:46:06.470321Z","shell.execute_reply":"2024-04-18T20:46:06.477349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/baseline_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:06.479882Z","iopub.execute_input":"2024-04-18T20:46:06.48016Z","iopub.status.idle":"2024-04-18T20:46:06.565832Z","shell.execute_reply.started":"2024-04-18T20:46:06.480137Z","shell.execute_reply":"2024-04-18T20:46:06.564976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore the balance of classes\nsns.countplot(df['label'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:06.567288Z","iopub.execute_input":"2024-04-18T20:46:06.567647Z","iopub.status.idle":"2024-04-18T20:46:06.685381Z","shell.execute_reply.started":"2024-04-18T20:46:06.567614Z","shell.execute_reply":"2024-04-18T20:46:06.684269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get all the rows with the value 0 in their category column\ndf = df[df['category'] == 1]\n\n# Examine dataset\nprint(df.head())\nprint(df.info())\n\n# Print all column names in the DataFrame\nprint(df.columns)\n\n# Explore text length distribution\ndf['text_length'] = df['claim'].apply(len)\nplt.figure(figsize=(10, 6))\nsns.histplot(df['text_length'], bins=40, kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:06.687846Z","iopub.execute_input":"2024-04-18T20:46:06.68849Z","iopub.status.idle":"2024-04-18T20:46:07.083173Z","shell.execute_reply.started":"2024-04-18T20:46:06.688454Z","shell.execute_reply":"2024-04-18T20:46:07.082288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\n\n# Download the necessary NLTK resources\nnltk.download('punkt')\n\n# Tokenize using NLTK's tokenizer\ntokens = df['claim'].apply(lambda x: word_tokenize(x))\n\n# Flatten and find unique tokens\nunique_words = set(token for sublist in tokens for token in sublist)\n\n# Calculate vocabulary size\nvocab_size = len(unique_words)\n\nprint(f\"The vocabulary size of the dataset is: {vocab_size}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:07.084734Z","iopub.execute_input":"2024-04-18T20:46:07.085107Z","iopub.status.idle":"2024-04-18T20:46:10.755199Z","shell.execute_reply.started":"2024-04-18T20:46:07.085072Z","shell.execute_reply":"2024-04-18T20:46:10.754299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare data for modeling\nx = df['claim']\ny = df['label']","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:10.756894Z","iopub.execute_input":"2024-04-18T20:46:10.757248Z","iopub.status.idle":"2024-04-18T20:46:10.762907Z","shell.execute_reply.started":"2024-04-18T20:46:10.757214Z","shell.execute_reply":"2024-04-18T20:46:10.762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)\n\nmy_tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nx_train = my_tfidf.fit_transform(x_train).toarray()\nx_test = my_tfidf.transform(x_test).toarray()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:10.76404Z","iopub.execute_input":"2024-04-18T20:46:10.764315Z","iopub.status.idle":"2024-04-18T20:46:12.312639Z","shell.execute_reply.started":"2024-04-18T20:46:10.764282Z","shell.execute_reply":"2024-04-18T20:46:12.311836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up vocabulary size\nvoc_size = 24194 #Category 1 Voc Size\n\n# One hot encoding\nonehot_repr = [one_hot(text, voc_size) for text in df['claim']]\n\n# Setting sentence length\nsent_length = 500  # category 1 max length\n\n# Padding the sentences\nembedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen=sent_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:12.313655Z","iopub.execute_input":"2024-04-18T20:46:12.313908Z","iopub.status.idle":"2024-04-18T20:46:12.634341Z","shell.execute_reply.started":"2024-04-18T20:46:12.313886Z","shell.execute_reply":"2024-04-18T20:46:12.633375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting training & validation loss and accuracy\ndef plot_metrics(history):\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss Over Epochs')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy Over Epochs')\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:12.636767Z","iopub.execute_input":"2024-04-18T20:46:12.637024Z","iopub.status.idle":"2024-04-18T20:46:12.643725Z","shell.execute_reply.started":"2024-04-18T20:46:12.637002Z","shell.execute_reply":"2024-04-18T20:46:12.642836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix and reports\ndef plot_confusion_matrix(cm, title='Confusion Matrix'):\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:12.644744Z","iopub.execute_input":"2024-04-18T20:46:12.645761Z","iopub.status.idle":"2024-04-18T20:46:12.655412Z","shell.execute_reply.started":"2024-04-18T20:46:12.645731Z","shell.execute_reply":"2024-04-18T20:46:12.654414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, GRU, Dropout, Dense\nfrom tensorflow.keras.metrics import Precision, Recall\n\nembedding_vector_features = 40\n\n# Assuming 'embedded_docs' is your input data and 'df['label']' is your label data\nX_final = np.array(embedded_docs)\ny_final = np.array(df['label'])  # Replace 'label' with your target column name\n\n# Train test split (common for both models)\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)\n\n# Setup Early Stopping\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n\n# Model 1: Simple LSTM\nmodel = Sequential()\nmodel.add(Embedding(voc_size, embedding_vector_features))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(100))  # Adding 100 LSTM neurons\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n\n# TensorBoard callback setup\nlog_dir = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n# Model training with history and TensorBoard\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[tensorboard_callback])\nplot_metrics(history)\n\n# Model 2: Bidirectional LSTM\nmodel1 = Sequential()\nmodel1.add(Embedding(voc_size, embedding_vector_features))\nmodel1.add(Dropout(0.5))\nmodel1.add(Bidirectional(LSTM(100)))\nmodel1.add(Dropout(0.5))\nmodel1.add(Dense(1, activation='sigmoid'))\nmodel1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\nprint(model1.summary())\n\n# TensorBoard callback setup\nlog_dir1 = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback1 = TensorBoard(log_dir=log_dir1, histogram_freq=1)\n\n# Model training with history and TensorBoard\nhistory1 = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[tensorboard_callback1])\nplot_metrics(history1)\n\n# Define the GRU model\nmodel_gru = Sequential()\nmodel_gru.add(Embedding(input_dim=voc_size, output_dim=embedding_vector_features))\nmodel_gru.add(GRU(100, return_sequences=True))  # First GRU layer with return_sequences=True to stack another GRU layer\nmodel_gru.add(Dropout(0.5))  # Dropout to prevent overfitting\nmodel_gru.add(GRU(64))  # Second GRU layer, no need for return_sequences as this is the last recurrent layer\nmodel_gru.add(Dropout(0.5))  # Additional dropout for regularization\nmodel_gru.add(Dense(64, activation='relu'))  # Dense layer after GRU layers\nmodel_gru.add(Dense(1, activation='sigmoid'))  # Output layer, using sigmoid for binary classification\nmodel_gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n\n# Summary of the GRU model\nprint(model_gru.summary())\n\n# TensorBoard callback setup\nlog_dir_gru = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback_gru = TensorBoard(log_dir=log_dir_gru, histogram_freq=1)\n\n# Model training with history and TensorBoard\nhistory_gru = model_gru.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[tensorboard_callback_gru])\nplot_metrics(history1)\n\n# Evaluate and compare both models using the test data\ny_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\ny_pred1 = (model1.predict(X_test) > 0.5).astype(\"int32\")\ny_pred_gru = (model_gru.predict(X_test) > 0.5).astype(\"int32\")\n\ncm = confusion_matrix(y_test, y_pred)\ncm1 = confusion_matrix(y_test, y_pred1)\ncm_gru = confusion_matrix(y_test, y_pred_gru)\n\nplot_confusion_matrix(cm, 'Model Confusion Matrix')\nprint(\"Model Accuracy Score:\", accuracy_score(y_test, y_pred))\nprint(\"Model Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\nplot_confusion_matrix(cm1, 'Model Confusion Matrix')\nprint(\"Model 2 Accuracy Score:\", accuracy_score(y_test, y_pred1))\nprint(\"Model 2 Classification Report:\")\nprint(classification_report(y_test, y_pred1))\n\nplot_confusion_matrix(cm_gru, 'Model Confusion Matrix')\nprint(\"Model 3 Accuracy Score:\", accuracy_score(y_test, y_pred_gru))\nprint(\"Model 3 Classification Report:\")\nprint(classification_report(y_test, y_pred_gru))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:46:12.656839Z","iopub.execute_input":"2024-04-18T20:46:12.657127Z","iopub.status.idle":"2024-04-18T20:49:37.802566Z","shell.execute_reply.started":"2024-04-18T20:46:12.657103Z","shell.execute_reply":"2024-04-18T20:49:37.801638Z"},"trusted":true},"execution_count":null,"outputs":[]}]}