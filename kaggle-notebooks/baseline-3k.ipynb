{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8031498,"sourceType":"datasetVersion","datasetId":4733994},{"sourceId":8032375,"sourceType":"datasetVersion","datasetId":4734646}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\n!pip install pip==24.0\n!pip install accelerate==0.28.0\n!pip install bitsandbytes==0.43.0\n!pip install numpy==1.26.4\n!pip install pandas==2.2.1\n!pip install scikit-learn==1.4.1.post1\n!pip install scikit-multilearn==0.2.0\n!pip install transformers==4.38.2\n!pip install peft==0.9.0\n!pip install torch==2.2.1\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:05:17.364236Z","iopub.execute_input":"2024-04-05T21:05:17.364598Z","iopub.status.idle":"2024-04-05T21:05:17.380507Z","shell.execute_reply.started":"2024-04-05T21:05:17.364568Z","shell.execute_reply":"2024-04-05T21:05:17.379381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:05:17.382267Z","iopub.execute_input":"2024-04-05T21:05:17.382889Z","iopub.status.idle":"2024-04-05T21:05:41.988047Z","shell.execute_reply.started":"2024-04-05T21:05:17.382857Z","shell.execute_reply":"2024-04-05T21:05:41.98687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:05:41.989583Z","iopub.execute_input":"2024-04-05T21:05:41.989975Z","iopub.status.idle":"2024-04-05T21:05:54.482586Z","shell.execute_reply.started":"2024-04-05T21:05:41.989934Z","shell.execute_reply":"2024-04-05T21:05:54.48159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:05:54.484926Z","iopub.execute_input":"2024-04-05T21:05:54.48522Z","iopub.status.idle":"2024-04-05T21:06:10.150934Z","shell.execute_reply.started":"2024-04-05T21:05:54.485195Z","shell.execute_reply":"2024-04-05T21:06:10.150073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:10.152742Z","iopub.execute_input":"2024-04-05T21:06:10.153554Z","iopub.status.idle":"2024-04-05T21:06:22.293785Z","shell.execute_reply.started":"2024-04-05T21:06:10.153516Z","shell.execute_reply":"2024-04-05T21:06:22.292805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade -q wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:24:35.437267Z","iopub.execute_input":"2024-04-05T21:24:35.438009Z","iopub.status.idle":"2024-04-05T21:24:47.725453Z","shell.execute_reply.started":"2024-04-05T21:24:35.437974Z","shell.execute_reply":"2024-04-05T21:24:47.724324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label. \n# If you use some other Label make sure to change the same below. \nwandb_api = user_secrets.get_secret(\"wandb_api\") \n\nwandb.login(key=wandb_api)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:24:53.074918Z","iopub.execute_input":"2024-04-05T21:24:53.075778Z","iopub.status.idle":"2024-04-05T21:24:57.025085Z","shell.execute_reply.started":"2024-04-05T21:24:53.075739Z","shell.execute_reply":"2024-04-05T21:24:57.024106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\nfrom datasets import Dataset, DatasetDict\nfrom peft import (\n    LoraConfig,\n    prepare_model_for_kbit_training,\n    get_peft_model\n)\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    get_linear_schedule_with_warmup\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:22.295149Z","iopub.execute_input":"2024-04-05T21:06:22.295458Z","iopub.status.idle":"2024-04-05T21:06:40.550161Z","shell.execute_reply.started":"2024-04-05T21:06:22.295426Z","shell.execute_reply":"2024-04-05T21:06:40.549267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:40.551334Z","iopub.execute_input":"2024-04-05T21:06:40.551934Z","iopub.status.idle":"2024-04-05T21:06:40.556318Z","shell.execute_reply.started":"2024-04-05T21:06:40.551902Z","shell.execute_reply":"2024-04-05T21:06:40.555238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seed for reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:40.55777Z","iopub.execute_input":"2024-04-05T21:06:40.558141Z","iopub.status.idle":"2024-04-05T21:06:40.797206Z","shell.execute_reply.started":"2024-04-05T21:06:40.558107Z","shell.execute_reply":"2024-04-05T21:06:40.796251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/baseline-dataset/baseline_dataset.csv')\n\n#df grab 3000 rows from each category, with 1500 of each label\ndf = df.groupby('category').head(3000).groupby('label').head(1500)\n\n# print the distrubution of the dataset\nprint(df['category'].value_counts())\nprint(df['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:40.79826Z","iopub.execute_input":"2024-04-05T21:06:40.798581Z","iopub.status.idle":"2024-04-05T21:06:40.971215Z","shell.execute_reply.started":"2024-04-05T21:06:40.798548Z","shell.execute_reply":"2024-04-05T21:06:40.970348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('category', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:40.974576Z","iopub.execute_input":"2024-04-05T21:06:40.974874Z","iopub.status.idle":"2024-04-05T21:06:40.980034Z","shell.execute_reply.started":"2024-04-05T21:06:40.974851Z","shell.execute_reply":"2024-04-05T21:06:40.978939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:40.981161Z","iopub.execute_input":"2024-04-05T21:06:40.981398Z","iopub.status.idle":"2024-04-05T21:06:40.991318Z","shell.execute_reply.started":"2024-04-05T21:06:40.981378Z","shell.execute_reply":"2024-04-05T21:06:40.990484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df display unique values in label column\nprint(df['label'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:40.992595Z","iopub.execute_input":"2024-04-05T21:06:40.99318Z","iopub.status.idle":"2024-04-05T21:06:41.002136Z","shell.execute_reply.started":"2024-04-05T21:06:40.993152Z","shell.execute_reply":"2024-04-05T21:06:41.001167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into text and labels\ntext = df['claim'].values\nlabels = df['label'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:41.003327Z","iopub.execute_input":"2024-04-05T21:06:41.003873Z","iopub.status.idle":"2024-04-05T21:06:41.012176Z","shell.execute_reply.started":"2024-04-05T21:06:41.003843Z","shell.execute_reply":"2024-04-05T21:06:41.011305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class weights for binary classification\nclass_counts = np.bincount(labels)\nclass_weights = torch.tensor([len(labels) / class_counts[1], len(labels) / class_counts[0]], dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:41.013433Z","iopub.execute_input":"2024-04-05T21:06:41.013895Z","iopub.status.idle":"2024-04-05T21:06:41.02203Z","shell.execute_reply.started":"2024-04-05T21:06:41.013865Z","shell.execute_reply":"2024-04-05T21:06:41.02102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\nx_train, x_val, y_train, y_val = train_test_split(text, labels, test_size=0.1, stratify=labels, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:41.023176Z","iopub.execute_input":"2024-04-05T21:06:41.023563Z","iopub.status.idle":"2024-04-05T21:06:41.041861Z","shell.execute_reply.started":"2024-04-05T21:06:41.023512Z","shell.execute_reply":"2024-04-05T21:06:41.040837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Hugging Face datasets\nds = DatasetDict({\n    'train': Dataset.from_dict({'text': x_train, 'labels': y_train}),\n    'val': Dataset.from_dict({'text': x_val, 'labels': y_val})\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:41.043023Z","iopub.execute_input":"2024-04-05T21:06:41.043291Z","iopub.status.idle":"2024-04-05T21:06:41.069298Z","shell.execute_reply.started":"2024-04-05T21:06:41.043269Z","shell.execute_reply":"2024-04-05T21:06:41.068544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model name\nmodel_name = 'mistralai/Mistral-7B-v0.1'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:41.070337Z","iopub.execute_input":"2024-04-05T21:06:41.070601Z","iopub.status.idle":"2024-04-05T21:06:42.52619Z","shell.execute_reply.started":"2024-04-05T21:06:41.070578Z","shell.execute_reply":"2024-04-05T21:06:42.525391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess dataset with tokenizer\ndef tokenize_examples(examples, tokenizer):\n    tokenized_inputs = tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n    tokenized_inputs['labels'] = examples['labels']\n    return tokenized_inputs\n\ntokenized_ds = ds.map(functools.partial(tokenize_examples, tokenizer=tokenizer), batched=True)\ntokenized_ds = tokenized_ds.with_format('torch')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:42.527345Z","iopub.execute_input":"2024-04-05T21:06:42.527635Z","iopub.status.idle":"2024-04-05T21:06:43.689443Z","shell.execute_reply.started":"2024-04-05T21:06:42.52761Z","shell.execute_reply":"2024-04-05T21:06:43.688491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# qunatization config\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\n# lora config\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)\n\n# load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=1\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:06:43.690668Z","iopub.execute_input":"2024-04-05T21:06:43.690956Z","iopub.status.idle":"2024-04-05T21:08:13.051814Z","shell.execute_reply.started":"2024-04-05T21:06:43.690933Z","shell.execute_reply":"2024-04-05T21:08:13.050706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define custom batch preprocessor\ndef collate_fn(batch, tokenizer):\n    dict_keys = ['input_ids', 'attention_mask', 'labels']\n    d = {k: [dic[k] for dic in batch] for k in dict_keys}\n    d['input_ids'] = torch.nn.utils.rnn.pad_sequence(\n        d['input_ids'], batch_first=True, padding_value=tokenizer.pad_token_id\n    )\n    d['attention_mask'] = torch.nn.utils.rnn.pad_sequence(\n        d['attention_mask'], batch_first=True, padding_value=0\n    )\n    d['labels'] = torch.stack(d['labels'])\n    return d\n\n# Custom Trainer for handling class weights in binary classification\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        if logits.shape[-1] == 1:\n            logits = logits.squeeze(-1)\n        labels = labels.float()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\n# Metrics computation for binary classification\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()\n    predictions = np.round(predictions)  # Threshold at 0.5\n    precision = precision_score(labels, predictions)\n    recall = recall_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average='weighted')\n    accuracy = accuracy_score(labels, predictions)\n\n    metrics = {\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'accuracy': accuracy\n    }\n\n    wandb.log(metrics)\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:08:13.053117Z","iopub.execute_input":"2024-04-05T21:08:13.053422Z","iopub.status.idle":"2024-04-05T21:08:13.064699Z","shell.execute_reply.started":"2024-04-05T21:08:13.053397Z","shell.execute_reply":"2024-04-05T21:08:13.063813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training args with gradient accumulation, learning rate scheduler, and early stopping\ntraining_args = TrainingArguments(\n    output_dir='baseline_binary_mistral_3000',\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    gradient_accumulation_steps=2,\n    num_train_epochs=4,\n    weight_decay=0.01,\n    evaluation_strategy='steps',\n    eval_steps=50,\n    save_steps=50,\n    load_best_model_at_end=True,\n    logging_steps=100,\n    fp16=True,\n    report_to='wandb',  # Enable wandb logging\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:08:13.06607Z","iopub.execute_input":"2024-04-05T21:08:13.06672Z","iopub.status.idle":"2024-04-05T21:08:15.415499Z","shell.execute_reply.started":"2024-04-05T21:08:13.066689Z","shell.execute_reply":"2024-04-05T21:08:15.414504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the number of training steps for the scheduler\nnum_training_steps = (len(tokenized_ds['train']) // training_args.per_device_train_batch_size) * training_args.num_train_epochs\n\n# Initialize optimizer and scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=0, \n    num_training_steps=num_training_steps\n)\n\n# Initialize the Trainer\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds['train'],\n    eval_dataset=tokenized_ds['val'],\n    tokenizer=tokenizer,\n    data_collator=functools.partial(collate_fn, tokenizer=tokenizer),\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, scheduler)\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:08:15.416858Z","iopub.execute_input":"2024-04-05T21:08:15.417515Z","iopub.status.idle":"2024-04-05T21:08:16.060609Z","shell.execute_reply.started":"2024-04-05T21:08:15.417479Z","shell.execute_reply":"2024-04-05T21:08:16.059703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.object = object\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:08:16.061862Z","iopub.execute_input":"2024-04-05T21:08:16.062195Z","iopub.status.idle":"2024-04-05T21:18:46.281274Z","shell.execute_reply.started":"2024-04-05T21:08:16.062163Z","shell.execute_reply":"2024-04-05T21:18:46.279062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save and load model\npeft_model_id = 'baseline_binary_mistral_3000'","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:18:46.282343Z","iopub.status.idle":"2024-04-05T21:18:46.282838Z","shell.execute_reply.started":"2024-04-05T21:18:46.282583Z","shell.execute_reply":"2024-04-05T21:18:46.282602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:18:46.284077Z","iopub.status.idle":"2024-04-05T21:18:46.284505Z","shell.execute_reply.started":"2024-04-05T21:18:46.284292Z","shell.execute_reply":"2024-04-05T21:18:46.284309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:18:46.28612Z","iopub.status.idle":"2024-04-05T21:18:46.286535Z","shell.execute_reply.started":"2024-04-05T21:18:46.28632Z","shell.execute_reply":"2024-04-05T21:18:46.286337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:18:46.28792Z","iopub.status.idle":"2024-04-05T21:18:46.288267Z","shell.execute_reply.started":"2024-04-05T21:18:46.288099Z","shell.execute_reply":"2024-04-05T21:18:46.288115Z"},"trusted":true},"execution_count":null,"outputs":[]}]}